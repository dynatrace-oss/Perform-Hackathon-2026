{
  "version": 4,
  "terraform_version": "1.5.7",
  "serial": 16,
  "lineage": "36ba7a73-b38c-3570-9658-de491012a520",
  "outputs": {
    "kubernetes_data_ingest_token": {
      "value": "dt0c01.T7IFBARLXQWCR6CMCBITSB4I.FXS4LC56LD3FQMMNWEK764GN53MAMWFWVTWY4ZGAP37NZJGXN2JMDRIBVNQ2OQLH",
      "type": "string",
      "sensitive": true
    },
    "kubernetes_operator_token": {
      "value": "dt0c01.JQUQ46TF5EF4NC57JQ4NDRTR.TL5HVFJO3XK3WTNA5FFTXK5FOWL26JXTQLUWKDTGAN3WV3OSFAEEXJLPAY4OU5OX",
      "type": "string",
      "sensitive": true
    }
  },
  "resources": [
    {
      "mode": "data",
      "type": "http",
      "name": "get_edge_connect",
      "provider": "provider[\"registry.terraform.io/hashicorp/http\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "body": "{\"items\":[{\"objectId\":\"vu9U3hXa3q0AAAABAC1hcHA6ZHluYXRyYWNlLmt1YmVybmV0ZXMuY29ubmVjdG9yOmNvbm5lY3Rpb24ABnRlbmFudAAGdGVuYW50ACQ4MTI3NzMyZC02OGI1LTM5YTktYjlmYS0xZjc4YzBmNGEwMjG-71TeFdrerQ\",\"value\":{\"name\":\"isitobservable-predectivescaling\",\"uid\":\"5f52f08a-6914-4b72-af15-798fb0f49a08\",\"namespace\":\"dynatrace\",\"token\":\"***310***\"}}],\"totalCount\":1,\"pageSize\":100}",
            "ca_cert_pem": null,
            "id": "https://ktp91462.live.dynatrace.com/api/v2/settings/objects?schemaIds=app:dynatrace.kubernetes.connector:connection\u0026filter=value.name='isitobservable-predectivescaling'",
            "insecure": null,
            "method": "GET",
            "request_body": null,
            "request_headers": {
              "Accept": "application/json",
              "Authorization": "Api-Token dt0c01.UJHRR3OHZWPNYJ74UQA2MDHQ.24AHBVJSIGBDANPXLQNWZ6PGYC6J3IEYUOZUBWMS63IHFFHYALIE3FUCF7YWCUSC"
            },
            "request_timeout_ms": null,
            "response_body": "{\"items\":[{\"objectId\":\"vu9U3hXa3q0AAAABAC1hcHA6ZHluYXRyYWNlLmt1YmVybmV0ZXMuY29ubmVjdG9yOmNvbm5lY3Rpb24ABnRlbmFudAAGdGVuYW50ACQ4MTI3NzMyZC02OGI1LTM5YTktYjlmYS0xZjc4YzBmNGEwMjG-71TeFdrerQ\",\"value\":{\"name\":\"isitobservable-predectivescaling\",\"uid\":\"5f52f08a-6914-4b72-af15-798fb0f49a08\",\"namespace\":\"dynatrace\",\"token\":\"***310***\"}}],\"totalCount\":1,\"pageSize\":100}",
            "response_body_base64": "eyJpdGVtcyI6W3sib2JqZWN0SWQiOiJ2dTlVM2hYYTNxMEFBQUFCQUMxaGNIQTZaSGx1WVhSeVlXTmxMbXQxWW1WeWJtVjBaWE11WTI5dWJtVmpkRzl5T21OdmJtNWxZM1JwYjI0QUJuUmxibUZ1ZEFBR2RHVnVZVzUwQUNRNE1USTNOek15WkMwMk9HSTFMVE01WVRrdFlqbG1ZUzB4WmpjNFl6Qm1OR0V3TWpHLTcxVGVGZHJlclEiLCJ2YWx1ZSI6eyJuYW1lIjoiaXNpdG9ic2VydmFibGUtcHJlZGVjdGl2ZXNjYWxpbmciLCJ1aWQiOiI1ZjUyZjA4YS02OTE0LTRiNzItYWYxNS03OThmYjBmNDlhMDgiLCJuYW1lc3BhY2UiOiJkeW5hdHJhY2UiLCJ0b2tlbiI6IioqKjMxMCoqKiJ9fV0sInRvdGFsQ291bnQiOjEsInBhZ2VTaXplIjoxMDB9",
            "response_headers": {
              "Cache-Control": "no-store, no-cache",
              "Content-Type": "application/json;charset=utf-8",
              "Date": "Fri, 21 Mar 2025 18:38:23 GMT",
              "Dynatrace-Response-Source": "Cluster",
              "Pragma": "no-cache",
              "Server": "ruxit server",
              "Server-Timing": "dtRpid;desc=\"-801718808\", dtSInfo;desc=\"0\"",
              "Set-Cookie": "dtCookie=v_4_srv_12_sn_41A7C7A83383F44D16EF84A1A7D00DBA_perc_100000_ol_0_mul_1_app-3Af6b10dd0df01cfe1_1_rcs-3Acss_0; Path=/; Domain=.dynatrace.com; secure",
              "Strict-Transport-Security": "max-age=31536000;includeSubDomains",
              "Vary": "Accept-Encoding",
              "X-Oneagent-Js-Injection": "true",
              "X-Robots-Tag": "noindex"
            },
            "retry": null,
            "status_code": 200,
            "url": "https://ktp91462.live.dynatrace.com/api/v2/settings/objects?schemaIds=app:dynatrace.kubernetes.connector:connection\u0026filter=value.name='isitobservable-predectivescaling'"
          },
          "sensitive_attributes": [
            [
              {
                "type": "get_attr",
                "value": "request_headers"
              },
              {
                "type": "index",
                "value": {
                  "value": "Authorization",
                  "type": "string"
                }
              }
            ]
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_api_token",
      "name": "kubernetes_data_ingest",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"].get_tokens",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "creation_date": "2025-03-21T18:35:39.796Z",
            "enabled": true,
            "expiration_date": "",
            "id": "dt0c01.T7IFBARLXQWCR6CMCBITSB4I",
            "last_used_date": "2025-03-21T18:37:27.730Z",
            "last_used_ip_address": "34.89.222.32",
            "modified_date": "",
            "name": "Kubernetes Data Ingest [Predictive Kubernetes Scaling]",
            "owner": "henrik.rexed@dynatrace.com",
            "personal_access_token": false,
            "scopes": [
              "logs.ingest",
              "metrics.ingest",
              "openTelemetryTrace.ingest"
            ],
            "token": "dt0c01.T7IFBARLXQWCR6CMCBITSB4I.FXS4LC56LD3FQMMNWEK764GN53MAMWFWVTWY4ZGAP37NZJGXN2JMDRIBVNQ2OQLH"
          },
          "sensitive_attributes": [],
          "private": "bnVsbA=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_api_token",
      "name": "kubernetes_operator",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"].get_tokens",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "creation_date": "2025-03-21T18:35:39.797Z",
            "enabled": true,
            "expiration_date": "",
            "id": "dt0c01.JQUQ46TF5EF4NC57JQ4NDRTR",
            "last_used_date": "2025-03-21T18:37:54.733Z",
            "last_used_ip_address": "10.176.210.18",
            "modified_date": "",
            "name": "Kubernetes Operator [Predictive Kubernetes Scaling]",
            "owner": "henrik.rexed@dynatrace.com",
            "personal_access_token": false,
            "scopes": [
              "DataExport",
              "InstallerDownload",
              "activeGateTokenManagement.create",
              "entities.read",
              "settings.read",
              "settings.write"
            ],
            "token": "dt0c01.JQUQ46TF5EF4NC57JQ4NDRTR.TL5HVFJO3XK3WTNA5FFTXK5FOWL26JXTQLUWKDTGAN3WV3OSFAEEXJLPAY4OU5OX"
          },
          "sensitive_attributes": [],
          "private": "bnVsbA=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_api_token",
      "name": "manage_workflows",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"].get_tokens",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "creation_date": "",
            "enabled": false,
            "expiration_date": "",
            "id": "dt0c01.SI4O6EGMDF3PDD4RVZVOVZMC",
            "last_used_date": "",
            "last_used_ip_address": "",
            "modified_date": "",
            "name": "Manage Workflow [Predictive Kubernetes Scaling]",
            "owner": "",
            "personal_access_token": false,
            "scopes": [
              "credentialVault.read",
              "credentialVault.write",
              "settings.read",
              "settings.write"
            ],
            "token": "dt0c01.SI4O6EGMDF3PDD4RVZVOVZMC.JWJVULJIE4XG65ODGOU4YG3MLNHLLP6I24HXJAXYDAFQDTORXGAANF76Y2GJTRDB"
          },
          "sensitive_attributes": [],
          "private": "bnVsbA=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_api_token",
      "name": "read_settings_objects",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"].get_tokens",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "creation_date": "",
            "enabled": false,
            "expiration_date": "",
            "id": "dt0c01.UJHRR3OHZWPNYJ74UQA2MDHQ",
            "last_used_date": "",
            "last_used_ip_address": "",
            "modified_date": "",
            "name": "Read Settings Objects [Predictive Kubernetes Scaling]",
            "owner": "",
            "personal_access_token": false,
            "scopes": [
              "settings.read"
            ],
            "token": "dt0c01.UJHRR3OHZWPNYJ74UQA2MDHQ.24AHBVJSIGBDANPXLQNWZ6PGYC6J3IEYUOZUBWMS63IHFFHYALIE3FUCF7YWCUSC"
          },
          "sensitive_attributes": [],
          "private": "bnVsbA=="
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_automation_workflow",
      "name": "commit_prediction",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "actor": "e641aa5e-dcc4-42e7-b87e-225a1ea96330",
            "description": "Reacts to events containing suggestions based on Davis resource usage prediction and applies them by creating a pull request on GitHub",
            "id": "d49b1b1b-e978-4289-bb20-d41811108845",
            "owner": "e641aa5e-dcc4-42e7-b87e-225a1ea96330",
            "private": true,
            "tasks": [
              {
                "task": [
                  {
                    "action": "dynatrace.automations:run-javascript",
                    "active": true,
                    "concurrency": "",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "create_pull_request": "OK"
                        }
                      }
                    ],
                    "description": "Trigger an event of type \"Custom Info\" and let other components react to it",
                    "input": "{\"script\":\"import {execution} from '@dynatrace-sdk/automation-utils';\\nimport {eventsClient, EventIngestEventType} from \\\"@dynatrace-sdk/client-classic-environment-v2\\\";\\n\\nexport default async function ({execution_id}) {\\n  const ex = await execution(execution_id);\\n  const pullRequest = (await ex.result('create_pull_request')).pullRequest;\\n  const event = ex.params.event;\\n\\n  const eventBody = {\\n    eventType: EventIngestEventType.CustomInfo,\\n    title: 'Applied Scaling Suggestion Because of Davis AI Prediction',\\n    entitySelector: `type(CLOUD_APPLICATION),entityName.equals(\\\"${event['kubernetes.predictivescaling.workload.name']}\\\"),namespaceName(\\\"${event['kubernetes.predictivescaling.workload.namespace']}\\\"),toRelationships.isClusterOfCa(type(KUBERNETES_CLUSTER),entityId(\\\"${event['kubernetes.predictivescaling.workload.cluster.id']}\\\"))`,\\n    properties: {\\n      'kubernetes.predictivescaling.type': 'SUGGEST_SCALING',\\n\\n      // Workload\\n      'kubernetes.predictivescaling.workload.cluster.name': event['kubernetes.predictivescaling.workload.cluster.name'],\\n      'kubernetes.predictivescaling.workload.cluster.id': event['kubernetes.predictivescaling.workload.cluster.id'],\\n      'kubernetes.predictivescaling.workload.kind': event['kubernetes.predictivescaling.workload.kind'],\\n      'kubernetes.predictivescaling.workload.namespace': event['kubernetes.predictivescaling.workload.namespace'],\\n      'kubernetes.predictivescaling.workload.name': event['kubernetes.predictivescaling.workload.name'],\\n      'kubernetes.predictivescaling.workload.uuid': event['kubernetes.predictivescaling.workload.uuid'],\\n      'kubernetes.predictivescaling.workload.limits.cpu': event['kubernetes.predictivescaling.workload.limits.cpu'],\\n      'kubernetes.predictivescaling.workload.limits.memory': event['kubernetes.predictivescaling.workload.limits.memory'],\\n\\n      // Prediction\\n      'kubernetes.predictivescaling.prediction.type': event['kubernetes.predictivescaling.prediction.type'],\\n      'kubernetes.predictivescaling.prediction.prompt': event['kubernetes.predictivescaling.prediction.prompt'],\\n      'kubernetes.predictivescaling.prediction.description': event['kubernetes.predictivescaling.prediction.description'],\\n      'kubernetes.predictivescaling.prediction.suggestions': event['kubernetes.predictivescaling.prediction.suggestions'],\\n\\n      // Target Utilization\\n      'kubernetes.predictivescaling.targetutilization.cpu.min': event['kubernetes.predictivescaling.targetutilization.cpu.min'],\\n      'kubernetes.predictivescaling.targetutilization.cpu.max': event['kubernetes.predictivescaling.targetutilization.cpu.max'],\\n      'kubernetes.predictivescaling.targetutilization.cpu.point': event['kubernetes.predictivescaling.targetutilization.cpu.point'],\\n      'kubernetes.predictivescaling.targetutilization.memory.min': event['kubernetes.predictivescaling.targetutilization.memory.min'],\\n      'kubernetes.predictivescaling.targetutilization.memory.max': event['kubernetes.predictivescaling.targetutilization.memory.max'],\\n      'kubernetes.predictivescaling.targetutilization.memory.point': event['kubernetes.predictivescaling.targetutilization.memory.point'],\\n\\n      // Target\\n      'kubernetes.predictivescaling.target.uuid': event['kubernetes.predictivescaling.target.uuid'],\\n      'kubernetes.predictivescaling.target.repository': event['kubernetes.predictivescaling.target.repository'],\\n\\n      // Pull Request\\n      'kubernetes.predictivescaling.pullrequest.id': `${pullRequest.id}`,\\n      'kubernetes.predictivescaling.pullrequest.url': pullRequest.url,\\n    },\\n  };\\n\\n  await eventsClient.createEvent({body: eventBody});\\n  return eventBody;\\n}\"}",
                    "name": "create_suggestion_applied_event",
                    "position": [
                      {
                        "x": 0,
                        "y": 6
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": ""
                  },
                  {
                    "action": "dynatrace.automations:run-javascript",
                    "active": true,
                    "concurrency": "",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "fetch_manifest": "OK"
                        }
                      }
                    ],
                    "description": "Uses the Davis CoPilot to apply all suggestions to the given manifest",
                    "input": "{\"script\":\"import {execution} from '@dynatrace-sdk/automation-utils';\\nimport {credentialVaultClient} from '@dynatrace-sdk/client-classic-environment-v2';\\nimport {getEnvironmentUrl} from '@dynatrace-sdk/app-environment'\\n\\nexport default async function ({execution_id}) {\\n  const ex = await execution(execution_id);\\n  var manifest = (await ex.result('fetch_manifest')).content;\\n  const event = ex.params.event;\\n\\n  const apiToken = await credentialVaultClient.getCredentialsDetails({\\n    id: \\\"CREDENTIALS_VAULT-E966991E87BB6431\\\",\\n  }).then((credentials) =\\u003e credentials.token);\\n\\n  const url = `${getEnvironmentUrl()}/platform/davis/copilot/v0.2/skills/conversations:message`;\\n\\n  const response = await fetch(url, {\\n    method: 'POST',\\n    headers: {\\n      'Authorization': `Bearer ${apiToken}`,\\n      'Content-Type': 'application/json'\\n    },\\n    body: JSON.stringify({\\n      text: `${event['kubernetes.predictivescaling.prediction.prompt']}\\\\n\\\\n${manifest}`\\n    })\\n  }).then(response =\\u003e response.json());\\n\\n  return {\\n    manifest: response.text.match(/(?\\u003c=^```(yaml|yml).*\\\\n)([^`])*(?=^```$)/gm)[0],\\n    time: new Date(event.timestamp).getTime(),\\n    description: event['kubernetes.predictivescaling.prediction.description']\\n  };\\n}\"}",
                    "name": "apply_suggestions",
                    "position": [
                      {
                        "x": 0,
                        "y": 3
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": ""
                  },
                  {
                    "action": "dynatrace.automations:run-javascript",
                    "active": true,
                    "concurrency": "",
                    "conditions": [],
                    "description": "Searches for the workload manifest on GitHub",
                    "input": "{\"script\":\"import {execution} from '@dynatrace-sdk/automation-utils';\\nimport {credentialVaultClient} from \\\"@dynatrace-sdk/client-classic-environment-v2\\\";\\n\\nexport default async function ({execution_id}) {\\n  const ex = await execution(execution_id);\\n  const event = ex.params.event;\\n\\n  const apiToken = await credentialVaultClient.getCredentialsDetails({\\n    id: \\\"CREDENTIALS_VAULT-D6558D93EEA4D1CA\\\",\\n  }).then((credentials) =\\u003e credentials.token);\\n\\n  // Search for file\\n  const url = 'https://api.github.com/search/code?q=' +\\n    `\\\"predictive-kubernetes-scaling.observability-labs.dynatrace.com/uuid:%20'${event['kubernetes.predictivescaling.target.uuid']}'\\\"` +\\n    `+repo:${event['kubernetes.predictivescaling.target.repository']}` +\\n    `+language:YAML`\\n\\n  const response = await fetch(url, {\\n    method: 'GET',\\n    headers: {\\n      'Authorization': `Bearer ${apiToken}`\\n    }\\n  }).then(response =\\u003e response.json());\\n\\n  const searchResult = response.items[0];\\n\\n  // Get default branch\\n  const repository = await fetch(searchResult.repository.url, {\\n    method: 'GET',\\n    headers: {\\n      'Authorization': `Bearer ${apiToken}`\\n    }\\n  }).then(response =\\u003e response.json());\\n\\n  return {\\n    owner: searchResult.repository.owner.login,\\n    repository: searchResult.repository.name,\\n    filePath: searchResult.path,\\n    defaultBranch: repository.default_branch\\n  }\\n}\"}",
                    "name": "find_manifest",
                    "position": [
                      {
                        "x": 0,
                        "y": 1
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": ""
                  },
                  {
                    "action": "dynatrace.github.connector:create-or-replace-file",
                    "active": true,
                    "concurrency": "",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "apply_suggestions": "OK"
                        }
                      }
                    ],
                    "description": "Updates the given manifest and pushes it to a new branch on GitHub",
                    "input": "{\"branch\":\"apply-davis-predictions-{{result(\\\"apply_suggestions\\\").time}}\",\"commitMessage\":\"Apply suggestions predicted by Davis AI:\\n\\n{{ result(\\\"apply_suggestions\\\").description }}\",\"connectionId\":\"vu9U3hXa3q0AAAABAClhcHA6ZHluYXRyYWNlLmdpdGh1Yi5jb25uZWN0b3I6Y29ubmVjdGlvbgAGdGVuYW50AAZ0ZW5hbnQAJGM4ZjY3OGE5LTZhM2UtMzg1Yy05MjM5LTA1MGVjMWU1OTQyNL7vVN4V2t6t\",\"createNewBranch\":true,\"fileContent\":\"{{ result(\\\"apply_suggestions\\\").manifest }}\",\"filePath\":\"{{ result(\\\"find_manifest\\\").filePath }}\",\"owner\":\"{{ result(\\\"find_manifest\\\").owner }}\",\"repository\":\"{{ result(\\\"find_manifest\\\").repository }}\",\"sourceBranch\":\"{{ result(\\\"find_manifest\\\").defaultBranch }}\"}",
                    "name": "update_manifest",
                    "position": [
                      {
                        "x": 0,
                        "y": 4
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": ""
                  },
                  {
                    "action": "dynatrace.github.connector:create-pull-request",
                    "active": true,
                    "concurrency": "",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "update_manifest": "OK"
                        }
                      }
                    ],
                    "description": "Creates a pull request that includes all suggested changes",
                    "input": "{\"connectionId\":\"vu9U3hXa3q0AAAABAClhcHA6ZHluYXRyYWNlLmdpdGh1Yi5jb25uZWN0b3I6Y29ubmVjdGlvbgAGdGVuYW50AAZ0ZW5hbnQAJGM4ZjY3OGE5LTZhM2UtMzg1Yy05MjM5LTA1MGVjMWU1OTQyNL7vVN4V2t6t\",\"description\":\"{{ result(\\\"apply_suggestions\\\").description }}\",\"owner\":\"{{ result(\\\"find_manifest\\\").owner }}\",\"repository\":\"{{ result(\\\"find_manifest\\\").repository }}\",\"sourceBranch\":\"apply-davis-predictions-{{result(\\\"apply_suggestions\\\").time}}\",\"targetBranch\":\"{{ result(\\\"find_manifest\\\").defaultBranch }}\",\"title\":\"Apply suggestions predicted by Dynatrace Davis AI\"}",
                    "name": "create_pull_request",
                    "position": [
                      {
                        "x": 0,
                        "y": 5
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": ""
                  },
                  {
                    "action": "dynatrace.github.connector:get-content",
                    "active": true,
                    "concurrency": "",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "find_manifest": "OK"
                        }
                      }
                    ],
                    "description": "Gets the content of the manifest",
                    "input": "{\"connectionId\":\"vu9U3hXa3q0AAAABAClhcHA6ZHluYXRyYWNlLmdpdGh1Yi5jb25uZWN0b3I6Y29ubmVjdGlvbgAGdGVuYW50AAZ0ZW5hbnQAJGM4ZjY3OGE5LTZhM2UtMzg1Yy05MjM5LTA1MGVjMWU1OTQyNL7vVN4V2t6t\",\"filePath\":\"{{ result(\\\"find_manifest\\\").filePath }}\",\"owner\":\"{{ result(\\\"find_manifest\\\").owner }}\",\"reference\":\"{{ result(\\\"find_manifest\\\").defaultBranch }}\",\"repository\":\"{{ result(\\\"find_manifest\\\").repository }}\"}",
                    "name": "fetch_manifest",
                    "position": [
                      {
                        "x": 0,
                        "y": 2
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": ""
                  }
                ]
              }
            ],
            "title": "Commit Davis Prediction [Predictive Kubernetes Scaling]",
            "trigger": [
              {
                "event": [
                  {
                    "active": true,
                    "config": [
                      {
                        "davis_event": [],
                        "davis_problem": [],
                        "event": [
                          {
                            "event_type": "events",
                            "query": "kubernetes.predictivescaling.type == \"DETECT_SCALING\""
                          }
                        ],
                        "type": "",
                        "value": ""
                      }
                    ]
                  }
                ],
                "schedule": []
              }
            ]
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "dynatrace_api_token.manage_workflows",
            "dynatrace_credentials.dynatrace_platform_token",
            "dynatrace_credentials.github_pat",
            "dynatrace_generic_setting.github_credentials"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_automation_workflow",
      "name": "predict_resource_usage",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "actor": "e641aa5e-dcc4-42e7-b87e-225a1ea96330",
            "description": "Predicts how much resources certain Kubernetes workloads will need in the future and emits events in case Kubernetes limits will be exceeded.",
            "id": "2b8717c4-c1d9-49ce-b625-61afd022c910",
            "owner": "e641aa5e-dcc4-42e7-b87e-225a1ea96330",
            "private": true,
            "tasks": [
              {
                "task": [
                  {
                    "action": "dynatrace.automations:execute-dql-query",
                    "active": true,
                    "concurrency": "",
                    "conditions": [],
                    "description": "Returns all Kubernetes workloads that should be scaled based on Davis predictions",
                    "input": "{\"failOnEmptyResult\":false,\"query\":\"fetch dt.entity.cloud_application, from:now() - 5m, to:now()\\n| filter kubernetesAnnotations[`predictive-kubernetes-scaling.observability-labs.dynatrace.com/enabled`] == \\\"true\\\"\\n| fields clusterId = clustered_by[`dt.entity.kubernetes_cluster`], namespace = namespaceName, name = entity.name, type = arrayFirst(cloudApplicationDeploymentTypes), annotations = kubernetesAnnotations\\n| join [ fetch dt.entity.kubernetes_cluster ],\\n  on: { left[clusterId] == right[id] },\\n  fields: { clusterName = entity.name }\"}",
                    "name": "find_workloads_to_scale",
                    "position": [
                      {
                        "x": 0,
                        "y": 1
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": ""
                  },
                  {
                    "action": "dynatrace.automations:run-javascript",
                    "active": true,
                    "concurrency": "",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "add_horizontal_scaling_suggestions": "OK",
                          "add_vertical_scaling_suggestions": "OK"
                        }
                      }
                    ],
                    "description": "Trigger a custom Davis event for each workload that needs scaling and let other automations react to it",
                    "input": "{\"script\":\"import {actionExecution} from \\\"@dynatrace-sdk/automation-utils\\\";\\nimport {eventsClient, EventIngestEventType} from \\\"@dynatrace-sdk/client-classic-environment-v2\\\";\\n\\nexport default async function ({action_execution_id}) {\\n  const actionEx = await actionExecution(action_execution_id);\\n  const workload = actionEx.loopItem.workload;\\n\\n  if (!workload.scalingSuggestions) {\\n    return;\\n  }\\n\\n  const prompts = [];\\n  const types = new Set([]);\\n\\n  workload.scalingSuggestions.prompts.forEach(prompt =\\u003e {\\n    prompts.push(prompt.prompt);\\n    types.add(prompt.type);\\n  });\\n\\n  const horizontalScalingConfig = workload.scalingConfig.horizontalScaling;\\n  let limits;\\n  if (horizontalScalingConfig.enabled) {\\n    limits = {\\n      cpu: horizontalScalingConfig.hpa.limits.cpu,\\n      memory: horizontalScalingConfig.hpa.limits.memory,\\n    }\\n  } else {\\n    limits = {\\n      cpu: workload.scalingConfig.limits.cpu,\\n      memory: workload.scalingConfig.limits.memory,\\n    }\\n  }\\n\\n  const targetUtilization = workload.scalingConfig.targetUtilization;\\n\\n  const event = {\\n    eventType: EventIngestEventType.CustomInfo,\\n    title: 'Suggesting to Scale Because of Davis AI Predictions',\\n    entitySelector: `type(CLOUD_APPLICATION),entityName.equals(\\\"${workload.name}\\\"),namespaceName(\\\"${workload.namespace}\\\"),toRelationships.isClusterOfCa(type(KUBERNETES_CLUSTER),entityId(\\\"${workload.clusterId}\\\"))`,\\n    properties: {\\n      'kubernetes.predictivescaling.type': 'DETECT_SCALING',\\n\\n      // Workload\\n      'kubernetes.predictivescaling.workload.cluster.name': workload.cluster,\\n      'kubernetes.predictivescaling.workload.cluster.id': workload.clusterId,\\n      'kubernetes.predictivescaling.workload.kind': workload.kind,\\n      'kubernetes.predictivescaling.workload.namespace': workload.namespace,\\n      'kubernetes.predictivescaling.workload.name': workload.name,\\n      'kubernetes.predictivescaling.workload.uuid': workload.uuid,\\n      'kubernetes.predictivescaling.workload.limits.cpu': limits.cpu,\\n      'kubernetes.predictivescaling.workload.limits.memory': limits.memory,\\n\\n      // Prediction\\n      'kubernetes.predictivescaling.prediction.type': [...types].join(','),\\n      'kubernetes.predictivescaling.prediction.prompt': prompts.join(' '),\\n      'kubernetes.predictivescaling.prediction.description': workload.scalingSuggestions.description,\\n      'kubernetes.predictivescaling.prediction.suggestions': JSON.stringify(workload.scalingSuggestions),\\n\\n      // Target Utilization\\n      'kubernetes.predictivescaling.targetutilization.cpu.min': targetUtilization.cpu.min,\\n      'kubernetes.predictivescaling.targetutilization.cpu.max': targetUtilization.cpu.max,\\n      'kubernetes.predictivescaling.targetutilization.cpu.point': targetUtilization.cpu.point,\\n      'kubernetes.predictivescaling.targetutilization.memory.min': targetUtilization.memory.min,\\n      'kubernetes.predictivescaling.targetutilization.memory.max': targetUtilization.memory.max,\\n      'kubernetes.predictivescaling.targetutilization.memory.point': targetUtilization.memory.point,\\n\\n      // Target\\n      'kubernetes.predictivescaling.target.uuid': horizontalScalingConfig.enabled ? horizontalScalingConfig.hpa.uuid : workload.uuid,\\n      'kubernetes.predictivescaling.target.repository': workload.repository,\\n    },\\n  }\\n\\n  await eventsClient.createEvent({body: event});\\n  return event;\\n}\"}",
                    "name": "create_scaling_events",
                    "position": [
                      {
                        "x": 0,
                        "y": 7
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": "workload in {{ result(\"add_horizontal_scaling_suggestions\") + result(\"add_vertical_scaling_suggestions\") }}"
                  },
                  {
                    "action": "dynatrace.automations:run-javascript",
                    "active": true,
                    "concurrency": "",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "adjust_limits": "OK"
                        }
                      }
                    ],
                    "description": "Add scaling suggestions to each workload that needs horizontal scaling",
                    "input": "{\"script\":\"import {actionExecution} from \\\"@dynatrace-sdk/automation-utils\\\";\\nimport {convert, units} from \\\"@dynatrace-sdk/units\\\";\\n\\nexport default async function ({action_execution_id}) {\\n  const actionEx = await actionExecution(action_execution_id);\\n  const workload = actionEx.loopItem.workload;\\n\\n  const targetUtilization = calculateTargetUtilization(workload.scalingConfig);\\n\\n  let newMaxReplicas = 0;\\n  const predictionsToApply = [];\\n  const descriptions = [];\\n  let exceedsLimits = false;\\n\\n  workload.predictions.forEach(prediction =\\u003e {\\n    let replicas = 0;\\n    if (prediction.resource === 'cpu' \\u0026\\u0026 prediction.value \\u003e targetUtilization.cpu.max) {\\n      predictionsToApply.push(prediction);\\n\\n      // Calculate new max replicas\\n      const newLimit = Math.ceil(prediction.value / workload.scalingConfig.targetUtilization.cpu.point);\\n      replicas = Math.ceil(newLimit / workload.scalingConfig.limits.cpu);\\n\\n      // Get description\\n      if (prediction.value \\u003e workload.scalingConfig.horizontalScaling.hpa.limits.cpu) {\\n        exceedsLimits = true;\\n        descriptions.push(`  - ⚠️ **CPU**: Predicted to exceed its CPU limit of \\\\`${workload.scalingConfig.horizontalScaling.hpa.limits.cpu}m\\\\` (\\\\`${workload.scalingConfig.limits.cpu}m * ${workload.scalingConfig.horizontalScaling.hpa.maxReplicas}\\\\`) at \\\\`${prediction.date.toString()}\\\\`)`)\\n      } else {\\n        const range = `${workload.scalingConfig.targetUtilization.cpu.min * 100}-${workload.scalingConfig.targetUtilization.cpu.max * 100}%`;\\n        descriptions.push(`  - ⬆️ **CPU**: Predicted to exceed its target range of ${range} at \\\\`${prediction.date.toString()}\\\\`)`)\\n      }\\n    } else if (prediction.resource === 'memory' \\u0026\\u0026 prediction.value \\u003e targetUtilization.memory.max) {\\n      predictionsToApply.push(prediction);\\n\\n      // Calculate new max replicas\\n      const newLimit = Math.ceil(prediction.value / workload.scalingConfig.targetUtilization.memory.point);\\n      replicas = Math.ceil(newLimit / workload.scalingConfig.limits.memory);\\n\\n      // Get description\\n      if (prediction.value \\u003e workload.scalingConfig.horizontalScaling.hpa.limits.memory) {\\n        exceedsLimits = true;\\n        const limit = `${convert(\\n          workload.scalingConfig.limits.memory,\\n          units.data.byte,\\n          units.data.mebibyte\\n        )}`;\\n        descriptions.push(`  - ⚠️ **Memory**: Predicted to exceed its Memory limit of \\\\`${limit * workload.scalingConfig.horizontalScaling.hpa.maxReplicas}Mi\\\\` (\\\\`${limit}Mi * ${workload.scalingConfig.horizontalScaling.hpa.maxReplicas}\\\\`) at \\\\`${prediction.date.toString()}\\\\`)`)\\n      } else {\\n        const range = `${workload.scalingConfig.targetUtilization.memory.min * 100}-${workload.scalingConfig.targetUtilization.memory.max * 100}%`;\\n        descriptions.push(`  - ⬆️ **Memory**: Predicted to exceed its target range of ${range} at \\\\`${prediction.date.toString()}\\\\`)`)\\n      }\\n    }\\n\\n    if (replicas \\u003e newMaxReplicas) {\\n      newMaxReplicas = replicas;\\n    }\\n  });\\n\\n  if (newMaxReplicas \\u003e 0) {\\n    const fullDescription = [\\n      `Davis AI has detected that the deployment anomaly-simulation can be scaled based on predictive AI analysis. Therefore, this PR applies the following actions:\\\\n`,\\n      `- ${exceedsLimits ? '⚠️' : '⬆️'} **HorizontalPodAutoscaler**: Scale the maximum number of replicas to \\\\`${newMaxReplicas}\\\\`:`,\\n      ...descriptions,\\n      `\\\\n_This Pull Request was automatically created by Davis CoPilot._`\\n    ];\\n    workload.scalingSuggestions = {\\n      description: fullDescription.join('\\\\n'),\\n      prompts: [{\\n        type: 'up',\\n        prompt: `Scale the maxReplicas of the HorizontalPodAutoscaler named \\\"${workload.scalingConfig.horizontalScaling.hpa.name}\\\" in this manifest to ${newMaxReplicas}.`,\\n        predictions: predictionsToApply\\n      }]\\n    };\\n  }\\n\\n  return workload;\\n}\\n\\nconst calculateTargetUtilization = (scalingConfig) =\\u003e {\\n  const limits = scalingConfig.horizontalScaling.hpa.limits;\\n  return {\\n    cpu: {\\n      max: limits.cpu * scalingConfig.targetUtilization.cpu.max,\\n      min: limits.cpu * scalingConfig.targetUtilization.cpu.min,\\n      point: limits.cpu * scalingConfig.targetUtilization.cpu.point\\n    },\\n    memory: {\\n      max: limits.memory * scalingConfig.targetUtilization.memory.max,\\n      min: limits.memory * scalingConfig.targetUtilization.memory.min,\\n      point: limits.memory * scalingConfig.targetUtilization.memory.point\\n    }\\n  };\\n}\"}",
                    "name": "add_horizontal_scaling_suggestions",
                    "position": [
                      {
                        "x": -1,
                        "y": 6
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": "workload in {{ result(\"adjust_limits\") }}"
                  },
                  {
                    "action": "dynatrace.automations:run-javascript",
                    "active": true,
                    "concurrency": "",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "get_hpa_manifests": "OK"
                        }
                      }
                    ],
                    "description": "Adjusts the CPU \u0026 Memory limit based on the HorizontalPodAutoscaler specification",
                    "input": "{\"script\":\"import {execution, actionExecution} from \\\"@dynatrace-sdk/automation-utils\\\";\\n\\nexport default async function ({execution_id, action_execution_id}) {\\n  const actionEx = await actionExecution(action_execution_id);\\n  const workload = actionEx.loopItem.workload;\\n\\n  // Get matching HPA manifest\\n  const ex = await execution(execution_id);\\n  const allHpaManifests = await ex.result('get_hpa_manifests');\\n\\n  const hpaManifest = allHpaManifests.find(manifest =\\u003e\\n    manifest.metadata.name === workload.scalingConfig.horizontalScaling.hpa.name\\n    \\u0026\\u0026 manifest.metadata.namespace === workload.namespace\\n    \\u0026\\u0026 manifest.spec.scaleTargetRef.name === workload.name\\n  );\\n\\n  // Adjust limits\\n  const maxReplicas = hpaManifest.spec.maxReplicas;\\n\\n  workload.scalingConfig.horizontalScaling.hpa = {\\n    ...workload.scalingConfig.horizontalScaling.hpa,\\n    maxReplicas,\\n    uuid: hpaManifest.metadata.annotations['predictive-kubernetes-scaling.observability-labs.dynatrace.com/uuid'],\\n    limits: {\\n      cpu: maxReplicas * workload.scalingConfig.limits.cpu,\\n      memory: maxReplicas * workload.scalingConfig.limits.memory\\n    }\\n  };\\n\\n  return workload;\\n}\"}",
                    "name": "adjust_limits",
                    "position": [
                      {
                        "x": -1,
                        "y": 5
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": "workload in [{% for workload in result(\"parse_predictions\") %}\n  {% if workload.scalingConfig.horizontalScaling.enabled %}\n    {{ workload }},\n  {% endif %}\n{% endfor %}]"
                  },
                  {
                    "action": "dynatrace.automations:run-javascript",
                    "active": true,
                    "concurrency": "",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "parse_predictions": "OK"
                        }
                      }
                    ],
                    "description": "Add scaling suggestions to each workload that needs vertical scaling",
                    "input": "{\"script\":\"import {actionExecution} from \\\"@dynatrace-sdk/automation-utils\\\";\\nimport {convert, units} from \\\"@dynatrace-sdk/units\\\";\\n\\nexport default async function ({action_execution_id}) {\\n  const actionEx = await actionExecution(action_execution_id);\\n  const workload = actionEx.loopItem.workload;\\n\\n  const targetUtilization = calculateTargetUtilization(workload.scalingConfig);\\n  const prompts = [];\\n  const descriptions = [`Davis AI has detected that the ${workload.kind} \\\\`${workload.name}\\\\` can be scaled based on predictive AI analysis. Therefore, this PR applies the following actions:\\\\n`];\\n\\n  workload.predictions.forEach(prediction =\\u003e {\\n    let resourceName;\\n    let newLimit;\\n    let range;\\n    let type;\\n    let exceedsLimit;\\n\\n    if (prediction.resource === 'cpu') {\\n      resourceName = 'CPU';\\n      newLimit = `${Math.ceil(prediction.value / workload.scalingConfig.targetUtilization.cpu.point)}m`;\\n      range = `${workload.scalingConfig.targetUtilization.cpu.min * 100}-${workload.scalingConfig.targetUtilization.cpu.max * 100}%`;\\n\\n      if (prediction.value \\u003e targetUtilization.cpu.max) {\\n        type = 'up';\\n      } else if (workload.scalingConfig.scaleDown \\u0026\\u0026 prediction.value \\u003c targetUtilization.cpu.min) {\\n        type = 'down';\\n      }\\n      exceedsLimit = type === 'up' \\u0026\\u0026 prediction.value \\u003e workload.scalingConfig.limits.cpu;\\n    } else if (prediction.resource === \\\"memory\\\") {\\n      resourceName = 'Memory';\\n      newLimit = `${Math.ceil(convert(\\n        Math.ceil(prediction.value / workload.scalingConfig.targetUtilization.memory.point),\\n        units.data.byte,\\n        units.data.mebibyte\\n      ))}Mi`;\\n      range = `${workload.scalingConfig.targetUtilization.memory.min * 100}-${workload.scalingConfig.targetUtilization.memory.max * 100}%`;\\n      if (prediction.value \\u003e targetUtilization.memory.max) {\\n        type = 'up';\\n      } else if (workload.scalingConfig.scaleDown \\u0026\\u0026 prediction.value \\u003c targetUtilization.memory.min) {\\n        type = 'down';\\n      }\\n      exceedsLimit = type === 'up' \\u0026\\u0026 prediction.value \\u003e workload.scalingConfig.limits.memory;\\n    }\\n\\n    const prompt = `Scale the ${resourceName} request \\u0026 limit of the ${workload.kind} named \\\"${workload.name}\\\" in this manifest to \\\\`${newLimit}\\\\`.`;\\n    let description = type === 'up'\\n      ? `- ⬆️ **${resourceName}**: Scale up to \\\\`${newLimit}\\\\` (predicted to exceed its target range of ${range} at \\\\`${prediction.date.toString()}\\\\`)`\\n      : `- ⬇️ **${resourceName}**: Scale down to \\\\`${newLimit}\\\\` (predicted to stay below its target range of ${range} until \\\\`${prediction.predictedUntil.toString()}\\\\`)`\\n    if (exceedsLimit) {\\n      description = `- ⚠️ **${resourceName}**: Scale up to \\\\`${newLimit}\\\\` (predicted to exceed its ${resourceName} limit at \\\\`${prediction.date.toString()}\\\\`)`\\n    }\\n    descriptions.push(description);\\n\\n    prompts.push({type, prompt, predictions: [prediction]});\\n  });\\n\\n  if (prompts.length \\u003e 0) {\\n    descriptions.push(`\\\\n_This Pull Request was automatically created by Davis CoPilot._`)\\n    workload.scalingSuggestions = {\\n      description: descriptions.join('\\\\n'),\\n      prompts\\n    };\\n  }\\n  return workload;\\n}\\n\\nconst calculateTargetUtilization = (scalingConfig) =\\u003e {\\n  return {\\n    cpu: {\\n      max: scalingConfig.limits.cpu * scalingConfig.targetUtilization.cpu.max,\\n      min: scalingConfig.limits.cpu * scalingConfig.targetUtilization.cpu.min,\\n      point: scalingConfig.limits.cpu * scalingConfig.targetUtilization.cpu.point\\n    },\\n    memory: {\\n      max: scalingConfig.limits.memory * scalingConfig.targetUtilization.memory.max,\\n      min: scalingConfig.limits.memory * scalingConfig.targetUtilization.memory.min,\\n      point: scalingConfig.limits.memory * scalingConfig.targetUtilization.memory.point\\n    }\\n  };\\n}\"}",
                    "name": "add_vertical_scaling_suggestions",
                    "position": [
                      {
                        "x": 1,
                        "y": 4
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": "workload in [{% for workload in result(\"parse_predictions\") %}\n  {% if workload.scalingConfig.horizontalScaling.enabled == false %}\n    {{ workload }},\n  {% endif %}\n{% endfor %}]"
                  },
                  {
                    "action": "dynatrace.automations:run-javascript",
                    "active": true,
                    "concurrency": "",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "predict_resource_usage": "OK"
                        }
                      }
                    ],
                    "description": "Parses the given Davis predictions and returns all workloads that need adjustments",
                    "input": "{\"script\":\"import {execution} from '@dynatrace-sdk/automation-utils';\\n\\nexport default async function ({execution_id}) {\\n  const ex = await execution(execution_id);\\n  const predictions = await ex.result('predict_resource_usage');\\n\\n  let workloads = [];\\n\\n  predictions.forEach(prediction =\\u003e {\\n    prediction.result.output\\n      .filter(output =\\u003e output.analysisStatus == 'OK' \\u0026\\u0026 output.forecastQualityAssessment == 'VALID')\\n      .forEach(output =\\u003e {\\n        const query = JSON.parse(output.analyzedTimeSeriesQuery.expression);\\n        const result = output.timeSeriesDataWithPredictions.records[0];\\n\\n        let resource = query.timeSeriesData.records[0].cpuUsage ? 'cpu' : 'memory';\\n        const highestPrediction = getHighestPrediction(result.timeframe, result.interval, resource, result['dt.davis.forecast:upper'])\\n        workloads = addOrUpdateWorkload(workloads, result, highestPrediction);\\n      })\\n  });\\n\\n  return workloads;\\n}\\n\\nconst getHighestPrediction = (timeframe, interval, resource, values) =\\u003e {\\n  const highestValue = Math.max(...values);\\n\\n  const index = values.indexOf(highestValue);\\n  const startTime = new Date(timeframe.start).getTime();\\n  const intervalInMs = interval / 1000000;\\n\\n  return {\\n    resource,\\n    value: highestValue,\\n    date: new Date(startTime + (index * intervalInMs)),\\n    predictedUntil: new Date(timeframe.end)\\n  }\\n}\\n\\nconst addOrUpdateWorkload = (workloads, result, prediction) =\\u003e {\\n  const existingWorkload = workloads.find(p =\\u003e\\n    p.cluster === result.cluster\\n    \\u0026\\u0026 p.namespace === result.namespace\\n    \\u0026\\u0026 p.kind === result.kind\\n    \\u0026\\u0026 p.name === result.name\\n  );\\n\\n  if (existingWorkload) {\\n    existingWorkload.predictions.push(prediction);\\n    return workloads;\\n  }\\n\\n  const annotations = JSON.parse(result.annotations.replaceAll(`'`, `\\\"`));\\n  const hpa = annotations['predictive-kubernetes-scaling.observability-labs.dynatrace.com/managed-by-hpa'];\\n\\n  workloads.push({\\n    cluster: result.cluster,\\n    clusterId: result.clusterId,\\n    namespace: result.namespace,\\n    kind: result.kind,\\n    name: result.name,\\n    repository: annotations['predictive-kubernetes-scaling.observability-labs.dynatrace.com/managed-by-repo'],\\n    uuid: annotations['predictive-kubernetes-scaling.observability-labs.dynatrace.com/uuid'],\\n    predictions: [prediction],\\n    scalingConfig: {\\n      horizontalScaling: {\\n        enabled: hpa ? true : false,\\n        hpa: {\\n          name: hpa\\n        }\\n      },\\n      limits: {\\n        memory: result.memoryLimit,\\n        cpu: result.cpuLimit,\\n      },\\n      targetUtilization: getTargetUtilization(annotations),\\n      scaleDown: annotations['predictive-kubernetes-scaling.observability-labs.dynatrace.com/scale-down'] ?? 'true' === 'true',\\n    }\\n  })\\n\\n  return workloads;\\n}\\n\\nconst getTargetUtilization = (annotations) =\\u003e {\\n  const defaultRange = annotations['predictive-kubernetes-scaling.observability-labs.dynatrace.com/target-utilization'] ?? '80-90';\\n  const targetUtilization = {};\\n\\n  const cpuRange = annotations['predictive-kubernetes-scaling.observability-labs.dynatrace.com/target-cpu-utilization'] ?? defaultRange;\\n  targetUtilization.cpu = getTargetUtilizationFromRange(cpuRange);\\n\\n  const memoryRange = annotations['predictive-kubernetes-scaling.observability-labs.dynatrace.com/target-memory-utilization'] ?? defaultRange;\\n  targetUtilization.memory = getTargetUtilizationFromRange(memoryRange);\\n\\n  return targetUtilization;\\n}\\n\\nconst getTargetUtilizationFromRange = (range) =\\u003e {\\n  const [min, max] = range.split('-').map(s =\\u003e parseInt(s) / 100);\\n  const point = (min + max) / 2;\\n  return {min, max, point};\\n}\"}",
                    "name": "parse_predictions",
                    "position": [
                      {
                        "x": 0,
                        "y": 3
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": ""
                  },
                  {
                    "action": "dynatrace.davis.workflow.actions:davis-analyze",
                    "active": true,
                    "concurrency": "1",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "find_workloads_to_scale": "OK"
                        }
                      }
                    ],
                    "description": "Predicts how much resources the given Kubernetes workloads will need",
                    "input": "{\"analyzerName\":\"dt.statistics.GenericForecastAnalyzer\",\"body\":{\"applyZeroLowerBoundHeuristic\":true,\"coverageProbability\":0.9,\"forecastHorizon\":100,\"forecastOffset\":0,\"generalParameters\":{\"logVerbosity\":\"WARNING\",\"resolveDimensionalQueryData\":false,\"timeframe\":{\"endTime\":\"now\",\"startTime\":\"now-1h\"}},\"nPaths\":200,\"timeSeriesData\":\"timeseries {\\n  memoryUsage = avg(dt.kubernetes.container.memory_working_set),\\n  memoryLimits = max(dt.kubernetes.container.limits_memory),\\n  cpuUsage = avg(dt.kubernetes.container.cpu_usage),\\n  cpuLimits = max(dt.kubernetes.container.limits_cpu)\\n},\\nby:{k8s.cluster.name, k8s.namespace.name, k8s.workload.kind, k8s.workload.name}\\n| filter k8s.cluster.name == \\\"{{ _.workload.clusterName }}\\\" and k8s.namespace.name == \\\"{{ _.workload.namespace }}\\\" and k8s.workload.name == \\\"{{ _.workload.name }}\\\"\\n| fields\\n  cluster = k8s.cluster.name,\\n  clusterId = \\\"{{ _.workload.clusterId }}\\\",\\n  namespace = k8s.namespace.name,\\n  kind = k8s.workload.kind,\\n  name = k8s.workload.name,\\n  annotations = \\\"{{ _.workload.annotations }}\\\",\\n  memoryLimit = arrayLast(memoryLimits),\\n  cpuLimit = arrayLast(cpuLimits),\\n  timeframe,\\n  interval,\\n  memoryUsage,\\n  cpuUsage\",\"useModelCache\":true}}",
                    "name": "predict_resource_usage",
                    "position": [
                      {
                        "x": 0,
                        "y": 2
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": "workload in {{ result(\"find_workloads_to_scale\")[\"records\"] }}"
                  },
                  {
                    "action": "dynatrace.kubernetes.connector:get-resource",
                    "active": true,
                    "concurrency": "",
                    "conditions": [
                      {
                        "custom": "",
                        "else": "STOP",
                        "states": {
                          "parse_predictions": "OK"
                        }
                      }
                    ],
                    "description": "Gets the manifests of the HorizontalPodAutoscalers that are associated to the given workloads",
                    "input": "{\"connection\":\"vu9U3hXa3q0AAAABAC1hcHA6ZHluYXRyYWNlLmt1YmVybmV0ZXMuY29ubmVjdG9yOmNvbm5lY3Rpb24ABnRlbmFudAAGdGVuYW50ACQ4MTI3NzMyZC02OGI1LTM5YTktYjlmYS0xZjc4YzBmNGEwMjG-71TeFdrerQ\",\"name\":\"{{ _.workload.name }}\",\"namespace\":\"{{ _.workload.namespace }}\",\"resourceType\":{\"apiVersion\":\"autoscaling/v2\",\"kind\":\"HorizontalPodAutoscaler\",\"name\":\"horizontalpodautoscalers\",\"namespaced\":true,\"shortNames\":[\"hpa\"],\"verbs\":[\"get\",\"list\"]}}",
                    "name": "get_hpa_manifests",
                    "position": [
                      {
                        "x": -1,
                        "y": 4
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": "workload in [{% for workload in result(\"parse_predictions\") %}\n  {% if workload.scalingConfig.horizontalScaling.enabled %}\n    {{ workload }},\n  {% endif %}\n{% endfor %}]"
                  }
                ]
              }
            ],
            "title": "Predict Kubernetes Resource Usage [Predictive Kubernetes Scaling]",
            "trigger": [
              {
                "event": [],
                "schedule": []
              }
            ]
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "data.http.get_edge_connect",
            "dynatrace_api_token.manage_workflows",
            "dynatrace_api_token.read_settings_objects"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_automation_workflow",
      "name": "react_to_resource_saturation",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "actor": "e641aa5e-dcc4-42e7-b87e-225a1ea96330",
            "description": "Is triggered when Davis detects a resource saturation problem and then triggers the 'Predict Kubernetes Resource Usage' workflow to create a Pull Request",
            "id": "be95b345-ef89-4714-9135-989de21e4502",
            "owner": "e641aa5e-dcc4-42e7-b87e-225a1ea96330",
            "private": true,
            "tasks": [
              {
                "task": [
                  {
                    "action": "dynatrace.automations:run-javascript",
                    "active": true,
                    "concurrency": "",
                    "conditions": [],
                    "description": "Triggers the 'Predict Kubernetes Resource Usage' workflow to react to problems",
                    "input": "{\"script\":\"import { workflowsClient } from \\\"@dynatrace-sdk/client-automation\\\";\\n\\nexport default async function ({ execution_id }) {\\n  return await workflowsClient.runWorkflow({\\n    id: \\\"2b8717c4-c1d9-49ce-b625-61afd022c910\\\",\\n    body: {},\\n  });\\n}\"}",
                    "name": "trigger_prediction",
                    "position": [
                      {
                        "x": 0,
                        "y": 1
                      }
                    ],
                    "retry": [],
                    "timeout": "900",
                    "with_items": ""
                  }
                ]
              }
            ],
            "title": "React to Resource Saturation [Predictive Kubernetes Scaling]",
            "trigger": [
              {
                "event": [
                  {
                    "active": false,
                    "config": [
                      {
                        "davis_event": [],
                        "davis_problem": [
                          {
                            "categories": [
                              {
                                "availability": false,
                                "custom": false,
                                "error": false,
                                "info": false,
                                "monitoring_unavailable": false,
                                "resource": true,
                                "slowdown": false
                              }
                            ],
                            "custom_filter": "",
                            "entity_tags": null,
                            "entity_tags_match": "",
                            "on_problem_close": false
                          }
                        ],
                        "event": [],
                        "type": "",
                        "value": ""
                      }
                    ]
                  }
                ],
                "schedule": []
              }
            ]
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "data.http.get_edge_connect",
            "dynatrace_api_token.manage_workflows",
            "dynatrace_api_token.read_settings_objects",
            "dynatrace_automation_workflow.predict_resource_usage"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_credentials",
      "name": "dynatrace_platform_token",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "allow_contextless_requests": true,
            "allowed_entities": [],
            "certificate": null,
            "credential_usage_summary": [],
            "description": null,
            "external": [],
            "format": null,
            "id": "CREDENTIALS_VAULT-E966991E87BB6431",
            "name": "Davis CoPilot API Token [Predictive Kubernetes Scaling]",
            "owner_access_only": null,
            "password": null,
            "public": null,
            "scope": null,
            "scopes": [
              "APP_ENGINE"
            ],
            "token": "dt0s16.JTSYBGE2.CVD5ASZTGPC73H3YLWVAULETIQ6WXXJX54UAXNXFYWLBIRXOB3FGNS2ZXXZJYJ7K",
            "username": null
          },
          "sensitive_attributes": [
            [
              {
                "type": "get_attr",
                "value": "token"
              }
            ]
          ],
          "private": "bnVsbA==",
          "dependencies": [
            "dynatrace_api_token.manage_workflows"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_credentials",
      "name": "github_pat",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "allow_contextless_requests": true,
            "allowed_entities": [],
            "certificate": null,
            "credential_usage_summary": [],
            "description": null,
            "external": [],
            "format": null,
            "id": "CREDENTIALS_VAULT-D6558D93EEA4D1CA",
            "name": "GitHub PAT [Predictive Kubernetes Scaling]",
            "owner_access_only": null,
            "password": null,
            "public": null,
            "scope": null,
            "scopes": [
              "APP_ENGINE"
            ],
            "token": "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",
            "username": null
          },
          "sensitive_attributes": [
            [
              {
                "type": "get_attr",
                "value": "token"
              }
            ]
          ],
          "private": "bnVsbA==",
          "dependencies": [
            "dynatrace_api_token.manage_workflows"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_document",
      "name": "accuracy_dashboard",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "actor": "",
            "content": "{\"layouts\":{\"1\":{\"h\":1,\"w\":12,\"x\":0,\"y\":0},\"10\":{\"h\":6,\"w\":11,\"x\":13,\"y\":7},\"2\":{\"h\":5,\"w\":12,\"x\":0,\"y\":1},\"3\":{\"h\":7,\"w\":4,\"x\":0,\"y\":6},\"4\":{\"h\":7,\"w\":8,\"x\":4,\"y\":6},\"5\":{\"h\":1,\"w\":11,\"x\":13,\"y\":0},\"6\":{\"h\":5,\"w\":4,\"x\":13,\"y\":1},\"7\":{\"h\":5,\"w\":4,\"x\":17,\"y\":1},\"8\":{\"h\":5,\"w\":3,\"x\":21,\"y\":1},\"9\":{\"h\":1,\"w\":11,\"x\":13,\"y\":6}},\"tiles\":{\"1\":{\"content\":\"# How Accurate Are the Predictions?\",\"type\":\"markdown\"},\"10\":{\"input\":\"import {queryExecutionClient} from '@dynatrace-sdk/client-query';\\n\\nexport default async function () {\\n  const eventsQuery = await queryExecutionClient.queryExecute({\\n    body: {\\n      query: `fetch events, timeframe: \\\"${$dt_timeframe_from}/${$dt_timeframe_to}\\\"\\n      | filter kubernetes.predictivescaling.type == \\\"SUGGEST_SCALING\\\"\\n      | filter in(kubernetes.predictivescaling.target.repository, array(\\\"${$repositories.join(\\\"\\\\\\\",\\\\\\\"\\\")}\\\"))`\\n    },\\n  });\\n\\n  const events = (await getQueryResult(eventsQuery)).records;\\n\\n  const predictions = [];\\n  const wrongEvents = [];\\n\\n  await Promise.all(events.map(async (event) =\\u003e {\\n    const scalingSuggestions = JSON.parse(event['kubernetes.predictivescaling.prediction.suggestions']);\\n\\n    await Promise.all(scalingSuggestions.prompts.map(async (prompt) =\\u003e {\\n      await Promise.all(prompt.predictions.map(async (prediction) =\\u003e {\\n        const actualMax = await getMaxUsage(event, prediction.resource, Date.parse(prediction.date));\\n        let state = 'Not enough data';\\n        if (actualMax) {\\n          const targetUtilization = getTargetUtilization(event, prediction.resource);\\n          const limit = prediction.value / targetUtilization[1];\\n          const lowerBound = Math.floor(limit * targetUtilization[0]);\\n          const upperBound = Math.ceil(limit * targetUtilization[2]);\\n\\n          if (actualMax \\u003e= lowerBound \\u0026\\u0026 actualMax \\u003c= upperBound) {\\n            state = 'Correct';\\n          } else if (actualMax \\u003e upperBound) {\\n            state = 'Too Low';\\n          } else {\\n            state = 'Too High';\\n          }\\n        }\\n\\n        if (state !== 'Correct' \\u0026\\u0026 state !== 'Not enough data') {\\n          event.reason = state;\\n          wrongEvents.push(event)\\n        }\\n      }));\\n    }));\\n  }));\\n\\n  return wrongEvents;\\n}\\n\\nconst getTargetUtilization = (event, resource) =\\u003e {\\n  if (resource === 'cpu') {\\n    return [\\n      event['kubernetes.predictivescaling.targetutilization.cpu.min'],\\n      event['kubernetes.predictivescaling.targetutilization.cpu.point'],\\n      event['kubernetes.predictivescaling.targetutilization.cpu.max'],\\n    ];\\n  }\\n  return [\\n    event['kubernetes.predictivescaling.targetutilization.memory.min'],\\n    event['kubernetes.predictivescaling.targetutilization.memory.point'],\\n    event['kubernetes.predictivescaling.targetutilization.memory.max'],\\n  ];\\n}\\n\\nconst getMaxUsage = async (event, resource, timestamp) =\\u003e {\\n  const metricName = resource === 'cpu' ? 'dt.kubernetes.container.cpu_usage' : 'dt.kubernetes.container.memory_working_set'\\n  // Check the predicted timestamp +/- 5 minutes\\n  const lookupQuery = await queryExecutionClient.queryExecute({\\n    body: {\\n      query: `timeseries cpuUsage = avg(${metricName}),\\n            by: {dt.entity.cloud_application},\\n            timeframe: \\\"${new Date(timestamp - 300000).toISOString()}/${new Date(timestamp + 300000).toISOString()}\\\"\\n            | filter dt.entity.cloud_application == \\\"${event['dt.entity.cloud_application']}\\\"\\n            | fields max = arrayMax(cpuUsage)`\\n    },\\n  });\\n  const actualUsage = (await getQueryResult(lookupQuery)).records;\\n\\n  if (actualUsage.length === 0) {\\n    return undefined;\\n  }\\n  return actualUsage[0].max;\\n}\\n\\nconst getQueryResult = async (query) =\\u003e {\\n  let state = 'RUNNING';\\n  let queryResult;\\n\\n  while (state === 'RUNNING') {\\n    // sleep a bit\\n    await new Promise(r =\\u003e setTimeout(r, 100));\\n    queryResult = await queryExecutionClient.queryPoll({\\n      requestToken: query.requestToken,\\n    });\\n    state = queryResult.state;\\n  }\\n\\n  return queryResult.result;\\n}\\n\",\"type\":\"code\",\"visualization\":\"table\",\"visualizationSettings\":{\"table\":{\"enableSparkLines\":false,\"hiddenColumns\":[[\"timestamp\"],[\"affected_entity_ids\"],[\"affected_entity_types\"],[\"dt.davis.impact_level\"],[\"dt.davis.is_frequent_event\"],[\"dt.davis.is_frequent_issue_detection_allowed\"],[\"dt.davis.mute.status\"],[\"dt.davis.timeout\"],[\"dt.entity.cloud_application\"],[\"dt.entity.cloud_application.name\"],[\"dt.source_entity\"],[\"dt.source_entity.type\"],[\"event.category\"],[\"event.end\"],[\"event.group_label\"],[\"event.id\"],[\"event.kind\"],[\"event.provider\"],[\"event.status\"],[\"event.status_transition\"],[\"event.type\"],[\"kubernetes.predictivescaling.prediction.description\"],[\"kubernetes.predictivescaling.prediction.prompt\"],[\"kubernetes.predictivescaling.pullrequest.id\"],[\"kubernetes.predictivescaling.target.repository\"],[\"kubernetes.predictivescaling.target.uuid\"],[\"kubernetes.predictivescaling.workload.cluster.id\"],[\"kubernetes.predictivescaling.workload.limits.cpu\"],[\"kubernetes.predictivescaling.workload.limits.memory\"],[\"kubernetes.predictivescaling.workload.uuid\"],[\"maintenance.is_under_maintenance\"],[\"prediction\"],[\"kubernetes.predictivescaling.prediction.suggestions\"],[\"kubernetes.predictivescaling.type\"]],\"rowDensity\":\"condensed\"}}},\"2\":{\"input\":\"import {queryExecutionClient} from '@dynatrace-sdk/client-query';\\n\\nexport default async function () {\\n  const eventsQuery = await queryExecutionClient.queryExecute({\\n    body: {\\n      query: `fetch events, timeframe: \\\"${$dt_timeframe_from}/${$dt_timeframe_to}\\\"\\n      | filter kubernetes.predictivescaling.type == \\\"SUGGEST_SCALING\\\"\\n      | filter in(kubernetes.predictivescaling.target.repository, array(\\\"${$repositories.join(\\\"\\\\\\\",\\\\\\\"\\\")}\\\"))`\\n    },\\n  });\\n\\n  const events = (await getQueryResult(eventsQuery)).records;\\n\\n\\n  const predictions = [];\\n\\n  await Promise.all(events.map(async (event) =\\u003e {\\n    const scalingSuggestions = JSON.parse(event['kubernetes.predictivescaling.prediction.suggestions']);\\n\\n    await Promise.all(scalingSuggestions.prompts.map(async (prompt) =\\u003e {\\n      await Promise.all(prompt.predictions.map(async (prediction) =\\u003e {\\n        const actualMax = await getMaxUsage(event, prediction.resource, Date.parse(prediction.date));\\n        let state = 'Not enough data';\\n        if (actualMax) {\\n          const targetUtilization = getTargetUtilization(event, prediction.resource);\\n          const limit = prediction.value / targetUtilization[1];\\n          const lowerBound = Math.floor(limit * targetUtilization[0]);\\n          const upperBound = Math.ceil(limit * targetUtilization[2]);\\n\\n          if (actualMax \\u003e= lowerBound \\u0026\\u0026 actualMax \\u003c= upperBound) {\\n            state = 'Correct';\\n          } else if (actualMax \\u003e upperBound) {\\n            state = 'Too Low';\\n          } else {\\n            state = 'Too High';\\n          }\\n        }\\n\\n        predictions.push({\\n          state,\\n          resource: prediction.resource,\\n          type: prompt.type\\n        })\\n\\n      }));\\n    }));\\n  }));\\n\\n  if (predictions.length === 0) {\\n    return;\\n  }\\n\\n  const correct = predictions.filter(p =\\u003e p.state === 'Correct').length;\\n  const ignored = predictions.filter(p =\\u003e p.state === 'Not enough data').length;\\n  const total = predictions.length - ignored;\\n\\n  return correct / total * 100;\\n}\\n\\nconst getTargetUtilization = (event, resource) =\\u003e {\\n  if (resource === 'cpu') {\\n    return [\\n      event['kubernetes.predictivescaling.targetutilization.cpu.min'],\\n      event['kubernetes.predictivescaling.targetutilization.cpu.point'],\\n      event['kubernetes.predictivescaling.targetutilization.cpu.max'],\\n    ];\\n  }\\n  return [\\n    event['kubernetes.predictivescaling.targetutilization.memory.min'],\\n    event['kubernetes.predictivescaling.targetutilization.memory.point'],\\n    event['kubernetes.predictivescaling.targetutilization.memory.max'],\\n  ];\\n}\\n\\nconst getMaxUsage = async (event, resource, timestamp) =\\u003e {\\n  const metricName = resource === 'cpu' ? 'dt.kubernetes.container.cpu_usage' : 'dt.kubernetes.container.memory_working_set'\\n  // Check the predicted timestamp +/- 5 minutes\\n  const lookupQuery = await queryExecutionClient.queryExecute({\\n    body: {\\n      query: `timeseries cpuUsage = avg(${metricName}),\\n            by: {dt.entity.cloud_application},\\n            timeframe: \\\"${new Date(timestamp - 300000).toISOString()}/${new Date(timestamp + 300000).toISOString()}\\\"\\n            | filter dt.entity.cloud_application == \\\"${event['dt.entity.cloud_application']}\\\"\\n            | fields max = arrayMax(cpuUsage)`\\n    },\\n  });\\n  const actualUsage = (await getQueryResult(lookupQuery)).records;\\n\\n  if (actualUsage.length === 0) {\\n    return undefined;\\n  }\\n  return actualUsage[0].max;\\n}\\n\\nconst getQueryResult = async (query) =\\u003e {\\n  let state = 'RUNNING';\\n  let queryResult;\\n\\n  while (state === 'RUNNING') {\\n    // sleep a bit\\n    await new Promise(r =\\u003e setTimeout(r, 100));\\n    queryResult = await queryExecutionClient.queryPoll({\\n      requestToken: query.requestToken,\\n    });\\n    state = queryResult.state;\\n  }\\n\\n  return queryResult.result;\\n}\\n\",\"title\":\"Score\",\"type\":\"code\",\"visualization\":\"singleValue\",\"visualizationSettings\":{\"singleValue\":{\"alignment\":\"center\",\"colorThresholdTarget\":\"background\",\"label\":\"\",\"recordField\":\"element\",\"showLabel\":false},\"thresholds\":[{\"field\":\"element\",\"isEnabled\":true,\"rules\":[{\"color\":{\"Default\":\"var(--dt-colors-charts-status-ideal-default, #2f6863)\"},\"comparator\":\"\\u003e=\",\"value\":80},{\"color\":{\"Default\":\"var(--dt-colors-charts-status-warning-default, #eca440)\"},\"comparator\":\"\\u003e=\",\"value\":50},{\"color\":{\"Default\":\"var(--dt-colors-charts-status-critical-default, #c4233b)\"},\"comparator\":\"=\",\"value\":0}]}],\"unitsOverrides\":{\"baseUnit\":\"none\",\"decimals\":0,\"delimiter\":false,\"displayUnit\":null,\"identifier\":\"element\",\"suffix\":\"%\",\"unitCategory\":\"unspecified\"}}},\"3\":{\"input\":\"import {queryExecutionClient} from '@dynatrace-sdk/client-query';\\n\\nexport default async function () {\\n  const eventsQuery = await queryExecutionClient.queryExecute({\\n    body: {\\n      query: `fetch events, timeframe: \\\"${$dt_timeframe_from}/${$dt_timeframe_to}\\\"\\n      | filter kubernetes.predictivescaling.type == \\\"SUGGEST_SCALING\\\"\\n      | filter in(kubernetes.predictivescaling.target.repository, array(\\\"${$repositories.join(\\\"\\\\\\\",\\\\\\\"\\\")}\\\"))`\\n    },\\n  });\\n\\n  const events = (await getQueryResult(eventsQuery)).records;\\n\\n  const predictions = [];\\n\\n  await Promise.all(events.map(async (event) =\\u003e {\\n    const scalingSuggestions = JSON.parse(event['kubernetes.predictivescaling.prediction.suggestions']);\\n\\n    await Promise.all(scalingSuggestions.prompts.map(async (prompt) =\\u003e {\\n      await Promise.all(prompt.predictions.map(async (prediction) =\\u003e {\\n        const actualMax = await getMaxUsage(event, prediction.resource, Date.parse(prediction.date));\\n        let state = 'Not enough data';\\n        if (actualMax) {\\n          const targetUtilization = getTargetUtilization(event, prediction.resource);\\n          const limit = prediction.value / targetUtilization[1];\\n          const lowerBound = Math.floor(limit * targetUtilization[0]);\\n          const upperBound = Math.ceil(limit * targetUtilization[2]);\\n\\n          if (actualMax \\u003e= lowerBound \\u0026\\u0026 actualMax \\u003c= upperBound) {\\n            state = 'Correct';\\n          } else if (actualMax \\u003e upperBound) {\\n            state = 'Too Low';\\n          } else {\\n            state = 'Too High';\\n          }\\n        }\\n\\n        predictions.push({\\n          state,\\n          resource: prediction.resource,\\n          type: prompt.type,\\n        })\\n\\n      }));\\n    }));\\n  }));\\n\\n  return [\\n    {state: 'Correct', count: predictions.filter(p =\\u003e p.state === 'Correct').length},\\n    {state: 'Too High', count: predictions.filter(p =\\u003e p.state === 'Too High').length},\\n    {state: 'Too Low', count: predictions.filter(p =\\u003e p.state === 'Too Low').length},\\n    {state: 'Not enough data', count: predictions.filter(p =\\u003e p.state === 'Not enough data').length},\\n  ];\\n}\\n\\nconst getTargetUtilization = (event, resource) =\\u003e {\\n  if (resource === 'cpu') {\\n    return [\\n      event['kubernetes.predictivescaling.targetutilization.cpu.min'],\\n      event['kubernetes.predictivescaling.targetutilization.cpu.point'],\\n      event['kubernetes.predictivescaling.targetutilization.cpu.max'],\\n    ];\\n  }\\n  return [\\n    event['kubernetes.predictivescaling.targetutilization.memory.min'],\\n    event['kubernetes.predictivescaling.targetutilization.memory.point'],\\n    event['kubernetes.predictivescaling.targetutilization.memory.max'],\\n  ];\\n}\\n\\nconst getMaxUsage = async (event, resource, timestamp) =\\u003e {\\n  const metricName = resource === 'cpu' ? 'dt.kubernetes.container.cpu_usage' : 'dt.kubernetes.container.memory_working_set'\\n  // Check the predicted timestamp +/- 5 minutes\\n  const lookupQuery = await queryExecutionClient.queryExecute({\\n    body: {\\n      query: `timeseries cpuUsage = avg(${metricName}),\\n            by: {dt.entity.cloud_application},\\n            timeframe: \\\"${new Date(timestamp - 300000).toISOString()}/${new Date(timestamp + 300000).toISOString()}\\\"\\n            | filter dt.entity.cloud_application == \\\"${event['dt.entity.cloud_application']}\\\"\\n            | fields max = arrayMax(cpuUsage)`\\n    },\\n  });\\n  const actualUsage = (await getQueryResult(lookupQuery)).records;\\n\\n  if (actualUsage.length === 0) {\\n    return undefined;\\n  }\\n  return actualUsage[0].max;\\n}\\n\\nconst getQueryResult = async (query) =\\u003e {\\n  let state = 'RUNNING';\\n  let queryResult;\\n\\n  while (state === 'RUNNING') {\\n    // sleep a bit\\n    await new Promise(r =\\u003e setTimeout(r, 100));\\n    queryResult = await queryExecutionClient.queryPoll({\\n      requestToken: query.requestToken,\\n    });\\n    state = queryResult.state;\\n  }\\n\\n  return queryResult.result;\\n}\\n\",\"type\":\"code\",\"visualization\":\"donutChart\",\"visualizationSettings\":{\"chartSettings\":{\"categoricalBarChartSettings\":{\"categoryAxis\":\"state\",\"valueAxis\":\"count\"},\"categoryOverrides\":{\"Correct\":{\"color\":\"var(--dt-colors-charts-apdex-excellent-default, #2a7453)\"},\"Not enough data\":{\"color\":\"var(--dt-colors-charts-categorical-color-05-default, #84859a)\"},\"Too High\":{\"color\":\"var(--dt-colors-charts-categorical-color-14-default, #d56b1a)\"},\"Too Low\":{\"color\":\"var(--dt-colors-charts-loglevel-emergency-default, #ae132d)\"}},\"circleChartSettings\":{\"groupingThresholdType\":\"relative\",\"groupingThresholdValue\":0,\"showTotalValue\":true,\"valueType\":\"relative\"}}}},\"4\":{\"input\":\"import {queryExecutionClient} from '@dynatrace-sdk/client-query';\\n\\nexport default async function () {\\n  const eventsQuery = await queryExecutionClient.queryExecute({\\n    body: {\\n      query: `fetch events, timeframe: \\\"${$dt_timeframe_from}/${$dt_timeframe_to}\\\"\\n      | filter kubernetes.predictivescaling.type == \\\"SUGGEST_SCALING\\\"\\n      | filter in(kubernetes.predictivescaling.target.repository, array(\\\"${$repositories.join(\\\"\\\\\\\",\\\\\\\"\\\")}\\\"))`\\n    },\\n  });\\n\\n  const events = (await getQueryResult(eventsQuery)).records;\\n\\n  const predictions = [];\\n\\n  await Promise.all(events.map(async (event) =\\u003e {\\n    const scalingSuggestions = JSON.parse(event['kubernetes.predictivescaling.prediction.suggestions']);\\n\\n    await Promise.all(scalingSuggestions.prompts.map(async (prompt) =\\u003e {\\n      await Promise.all(prompt.predictions.map(async (prediction) =\\u003e {\\n        const actualMax = await getMaxUsage(event, prediction.resource, Date.parse(prediction.date));\\n        let state = 'Not enough data';\\n        if (actualMax) {\\n          const targetUtilization = getTargetUtilization(event, prediction.resource);\\n          const limit = prediction.value / targetUtilization[1];\\n          const lowerBound = Math.floor(limit * targetUtilization[0]);\\n          const upperBound = Math.ceil(limit * targetUtilization[2]);\\n\\n          if (actualMax \\u003e= lowerBound \\u0026\\u0026 actualMax \\u003c= upperBound) {\\n            state = 'Correct';\\n          } else if (actualMax \\u003e upperBound) {\\n            state = 'Too Low';\\n          } else {\\n            state = 'Too High';\\n          }\\n        }\\n\\n        predictions.push({\\n          state,\\n          resource: prediction.resource,\\n          type: prompt.type,\\n        })\\n\\n      }));\\n    }));\\n  }));\\n\\n  return predictions;\\n}\\n\\nconst getTargetUtilization = (event, resource) =\\u003e {\\n  if (resource === 'cpu') {\\n    return [\\n      event['kubernetes.predictivescaling.targetutilization.cpu.min'],\\n      event['kubernetes.predictivescaling.targetutilization.cpu.point'],\\n      event['kubernetes.predictivescaling.targetutilization.cpu.max'],\\n    ];\\n  }\\n  return [\\n    event['kubernetes.predictivescaling.targetutilization.memory.min'],\\n    event['kubernetes.predictivescaling.targetutilization.memory.point'],\\n    event['kubernetes.predictivescaling.targetutilization.memory.max'],\\n  ];\\n}\\n\\nconst getMaxUsage = async (event, resource, timestamp) =\\u003e {\\n  const metricName = resource === 'cpu' ? 'dt.kubernetes.container.cpu_usage' : 'dt.kubernetes.container.memory_working_set'\\n  // Check the predicted timestamp +/- 5 minutes\\n  const lookupQuery = await queryExecutionClient.queryExecute({\\n    body: {\\n      query: `timeseries cpuUsage = avg(${metricName}),\\n            by: {dt.entity.cloud_application},\\n            timeframe: \\\"${new Date(timestamp - 300000).toISOString()}/${new Date(timestamp + 300000).toISOString()}\\\"\\n            | filter dt.entity.cloud_application == \\\"${event['dt.entity.cloud_application']}\\\"\\n            | fields max = arrayMax(cpuUsage)`\\n    },\\n  });\\n  const actualUsage = (await getQueryResult(lookupQuery)).records;\\n\\n  if (actualUsage.length === 0) {\\n    return undefined;\\n  }\\n  return actualUsage[0].max;\\n}\\n\\nconst getQueryResult = async (query) =\\u003e {\\n  let state = 'RUNNING';\\n  let queryResult;\\n\\n  while (state === 'RUNNING') {\\n    // sleep a bit\\n    await new Promise(r =\\u003e setTimeout(r, 100));\\n    queryResult = await queryExecutionClient.queryPoll({\\n      requestToken: query.requestToken,\\n    });\\n    state = queryResult.state;\\n  }\\n\\n  return queryResult.result;\\n}\\n\",\"type\":\"code\",\"visualization\":\"honeycomb\",\"visualizationSettings\":{\"honeycomb\":{\"colorMode\":\"custom-colors\",\"colorPalette\":\"categorical\",\"customColors\":[{\"color\":{\"Default\":\"var(--dt-colors-charts-categorical-color-09-default, #649438)\"},\"comparator\":\"=\",\"value\":\"Correct\"},{\"color\":{\"Default\":\"var(--dt-colors-charts-loglevel-severe-default, #d56b1a)\"},\"comparator\":\"=\",\"value\":\"Too High\"},{\"color\":{\"Default\":\"var(--dt-colors-charts-categorical-color-12-default, #cd3741)\"},\"comparator\":\"=\",\"value\":\"Too Low\"},{\"color\":{\"Default\":\"var(--dt-colors-charts-logstatus-none-default, #2c2f3f)\"},\"comparator\":\"=\",\"value\":\"Not enough data\"}],\"dataMappings\":{\"value\":\"state\"},\"displayedFields\":[\"resource\"],\"legend\":{\"hidden\":false,\"position\":\"auto\"},\"shape\":\"hexagon\"}}},\"5\":{\"content\":\"# How Many Predictions Have Been Applied?\",\"type\":\"markdown\"},\"6\":{\"davis\":{\"enabled\":false},\"query\":\"fetch events\\n| filter kubernetes.predictivescaling.type == \\\"SUGGEST_SCALING\\\"\\n| filter in(kubernetes.predictivescaling.target.repository, array($repositories))\\n| summarize count()\\n\",\"title\":\"New Pull Requests\",\"type\":\"data\",\"visualization\":\"singleValue\",\"visualizationSettings\":{\"singleValue\":{\"alignment\":\"center\",\"recordField\":\"count()\",\"showLabel\":false}}},\"7\":{\"davis\":{\"enabled\":false},\"query\":\"fetch events\\n| filter dt.openpipeline.source == \\\"/platform/ingest/custom/events/github\\\"\\n| parse repository, \\\"JSON:repo\\\"\\n| filter in(repo[full_name], array($repositories))\\n| filter action == \\\"merged\\\"\\n| summarize count()\\n\",\"title\":\"Merged Pull Requests\",\"type\":\"data\",\"visualization\":\"singleValue\",\"visualizationSettings\":{\"singleValue\":{\"alignment\":\"center\",\"recordField\":\"count()\",\"showLabel\":false}}},\"8\":{\"davis\":{\"enabled\":false},\"query\":\"fetch events\\n| filter dt.openpipeline.source == \\\"/platform/ingest/custom/events/github\\\"\\n| parse repository, \\\"JSON:repo\\\"\\n| filter in(repo[full_name], array($repositories))\\n| filter action == \\\"closed\\\"\\n| summarize count()\\n\",\"title\":\"Closed Pull Requests\",\"type\":\"data\",\"visualization\":\"singleValue\",\"visualizationSettings\":{\"singleValue\":{\"alignment\":\"center\",\"recordField\":\"count()\",\"showLabel\":false}}},\"9\":{\"content\":\"# Which Predictions Have Been Wrong?\",\"type\":\"markdown\"}},\"variables\":[{\"input\":\"fetch events | filter kubernetes.predictivescaling.type == \\\"SUGGEST_SCALING\\\" | fields kubernetes.predictivescaling.target.repository\",\"key\":\"repositories\",\"multiple\":true,\"type\":\"query\",\"visible\":true}]}",
            "id": "edfb1a02-ed92-4509-94d8-c9695922bbf7",
            "name": "Predictive Kubernetes Scaling Accuracy",
            "owner": "e641aa5e-dcc4-42e7-b87e-225a1ea96330",
            "private": true,
            "type": "dashboard",
            "version": 1
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "dynatrace_api_token.manage_workflows"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_document",
      "name": "notebook",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "actor": "",
            "content": "{\"defaultTimeframe\":{\"from\":\"now()-1h\",\"to\":\"now()\"},\"sections\":[{\"id\":\"ab5431e7-83bb-47c9-a6d0-ad933be56e20\",\"markdown\":\"# Predictive Kubernetes Scaling\\n\\nStruggling to keep up with the demands of dynamic Kubernetes environments? Manual scaling is not only time-consuming and reactive but also prone to errors. We're harnessing the power of Dynatrace Automations and Davis AI to predict resource bottlenecks and automatically open pull requests to scale applications. This proactive approach minimizes downtime, helps you to optimize resource utilization, and ensures your applications perform at their best.\\n\\nWe achieve this by combining predictive AI to forecast resource limitations with generative AI to modify Kubernetes manifests on GitHub by creating pull requests for scaling adjustments. If you'd like a closer look at how this works, check out the following sections.\\n\\n\\u003e This notebook does not do any scaling. It is just an additional resource that helps you to understand how the actual automation can be done by [Dynatrace Workflows](https://www.dynatrace.com/platform/workflows/). If you want to try this yourself, you can run a full demo in your own Dynatrace tenant using [this demo](https://github.com/Dynatrace/obslab-predictive-kubernetes-scaling).\\\"\\n\",\"type\":\"markdown\"},{\"id\":\"aaabe140-3570-4d58-a56b-af5c06dca5d1\",\"markdown\":\"## 1. Find Workloads to Scale\\n\\nTo kick things off, we need to identify the Kubernetes workloads our automation workflow will manage. While theoretically we could include all workloads, that might lead to lengthy workflow execution times. Instead, we've opted to focus on Kubernetes workloads where the annotation `predictive-kubernetes-scaling.observability-labs.dynatrace.com/enabled` is set to `true`.\\n\\nThe following Dynatrace Query Language (DQL) query shows these selected workloads.\\n\",\"type\":\"markdown\"},{\"height\":250,\"id\":\"de2945f0-ce42-4fdc-9b20-ca6076cc7d8d\",\"showTitle\":false,\"state\":{\"input\":{\"timeframe\":{\"from\":\"-5m\",\"to\":\"now()\"},\"value\":\"fetch dt.entity.cloud_application\\n| filter kubernetesAnnotations[`predictive-kubernetes-scaling.observability-labs.dynatrace.com/enabled`] == \\\"true\\\"\\n| fields k8s.cluster.id = clustered_by[`dt.entity.kubernetes_cluster`], k8s.namespace.name = namespaceName, k8s.workload.name = entity.name, k8s.workload.annotations = kubernetesAnnotations, type = arrayFirst(cloudApplicationDeploymentTypes)\\n| join [ fetch dt.entity.kubernetes_cluster ],\\n  on: { left[k8s.cluster.id] == right[id] },\\n  fields: { k8s.cluster.name = entity.name }\\n| fields type, k8s.cluster.name, k8s.cluster.id, k8s.namespace.name, k8s.workload.name, k8s.workload.annotations\"},\"visualization\":\"table\"},\"type\":\"dql\"},{\"id\":\"af27fbe8-e4b7-4c39-bcaf-247a3b5f5cfa\",\"markdown\":\"## 2. Predict Resource Usage\\n\\nWith our target workloads identified, we'll utilize Dynatrace Davis AI to forecast their future CPU and memory consumption. This will help us determine if they're likely to exceed their defined Kubernetes resource limits.\\n\\nTo get a sneak peek of the prediction query that will be used in the workflow, you can execute the following DQL query.\\n\\n\\u003e **Note**: The query result will include two entries per workload, one for predicted CPU usage and one for predicted memory usage.\\n\",\"type\":\"markdown\"},{\"height\":600,\"id\":\"d88e4bb9-d763-4e74-9750-523c4db93dc3\",\"showTitle\":false,\"state\":{\"davis\":{\"componentState\":{\"inputData\":{\"dt.statistics.ui.ForecastAnalyzer\":{\"forecastHorizon\":100,\"forecastOffset\":1,\"generalParameters\":{\"resolveDimensionalQueryData\":true,\"timeframe\":{\"endTime\":\"now()\",\"startTime\":\"now()-1h\"}},\"query\":\"timeseries {\\n  memoryUsage = avg(dt.kubernetes.container.memory_working_set),\\n  cpuUsage = avg(dt.kubernetes.container.cpu_usage)\\n},\\nby:{k8s.cluster.name, k8s.namespace.name, k8s.workload.kind, k8s.workload.name}\\n| filter k8s.cluster.name == \\\"predictive-kubernetes-scaling-demo\\\" and k8s.workload.name == \\\"anomaly-simulation\\\"\"}},\"selectedAnalyzerName\":\"dt.statistics.ui.ForecastAnalyzer\"},\"enabled\":true},\"input\":{\"timeframe\":{\"from\":\"now()-1h\",\"to\":\"now()\"},\"value\":\"timeseries {\\n  memoryUsage = avg(dt.kubernetes.container.memory_working_set),\\n  cpuUsage = avg(dt.kubernetes.container.cpu_usage)\\n},\\nby:{k8s.cluster.name, k8s.namespace.name, k8s.workload.kind, k8s.workload.name}\\n| filter k8s.cluster.name == \\\"predictive-kubernetes-scaling-demo\\\" and k8s.workload.name == \\\"anomaly-simulation\\\"\"},\"querySettings\":{\"defaultSamplingRatio\":10,\"defaultScanLimitGbytes\":500,\"enableSampling\":false,\"maxResultMegaBytes\":1,\"maxResultRecords\":1000},\"visualization\":\"davis\"},\"type\":\"dql\"},{\"id\":\"66c1701b-4883-4ff0-a15d-a978aa8016cf\",\"markdown\":\"### 3. Emit Events\\n\\nThe final step of the first workflow is to analyze the prediction results and emit a Davis event of type `CUSTOM_INFO` for each workload that needs scaling. This event is associated with the respective Kubernetes workload and includes the scaling prompt and the reasoning behind the decision. By emitting these events, we enable other automations to react and trigger the necessary scaling adjustments.\\n\\nTo get a preview of these events, execute the following DQL query.\\n\",\"type\":\"markdown\"},{\"height\":250,\"id\":\"97e574bd-e2c4-427e-b05a-945a93cf6a52\",\"showTitle\":false,\"state\":{\"input\":{\"timeframe\":{\"from\":\"now()-1h\",\"to\":\"now()\"},\"value\":\"fetch events\\n| filter event.type == \\\"CUSTOM_INFO\\\" and kubernetes.predictivescaling.type == \\\"DETECT_SCALING\\\"\\n| fields\\n  timestamp,\\n  event.name,\\n  event.category,\\n  event.type,\\n  kubernetes.predictivescaling.workload.cluster.name,\\n  kubernetes.predictivescaling.workload.cluster.id,\\n  kubernetes.predictivescaling.workload.kind,\\n  kubernetes.predictivescaling.workload.namespace,\\n  kubernetes.predictivescaling.workload.name,\\n  kubernetes.predictivescaling.workload.uuid,\\n  kubernetes.predictivescaling.workload.limits.memory,\\n  kubernetes.predictivescaling.workload.limits.cpu,\\n  kubernetes.predictivescaling.prediction.type,\\n  kubernetes.predictivescaling.prediction.prompt,\\n  kubernetes.predictivescaling.prediction.description,\\n  kubernetes.predictivescaling.prediction.suggestions,\\n  kubernetes.predictivescaling.target.uuid,\\n  kubernetes.predictivescaling.target.repository\"},\"visualization\":\"table\"},\"type\":\"dql\"},{\"id\":\"402a7e81-541a-4808-be25-50b717aeaafe\",\"markdown\":\"## 4. Apply Suggestions\\n\\nThat wraps up the first workflow. In essence, it identifies workloads to scale, predicts their resource usage, and emits events signaling the need for scaling adjustments. These events then trigger a second workflow that takes over the actual scaling process.\\n\\nWhile we can't demonstrate this second workflow through DQL queries here, you can explore it firsthand by running [this demo](https://github.com/Dynatrace/obslab-predictive-kubernetes-scaling). Here's what the second workflow does in a nutshell:\\n\\n- **Search for the Deployment Manifest on GitHub**: The workflow locates the relevant Kubernetes deployment manifest in your GitHub repository. It identifies the correct repository using the `predictive-kubernetes-scaling.observability-labs.dynatrace.com/managed-by-repo` annotation and then utilizes the GitHub Search API to find the correct file.\\n- **Apply Suggestions with Davis CoPilot**: The workflow uses [Davis CoPilot](https://www.dynatrace.com/news/blog/hypermodal-ai-dynatrace-expands-davis-ai-with-davis-copilot/) to apply the scaling suggestions to the fetched manifest. This step intelligently modifies the manifest to reflect the required resource adjustments.\\n- **Create a Pull Request on GitHub**: Finally, the workflow employs the GitHub for Workflows app to create a pull request on GitHub, proposing the changes to the deployment manifest. This PR can then be reviewed and merged to implement the scaling updates in your Kubernetes environment.\\n\\n![GitHub Pull Request](https://raw.githubusercontent.com/Dynatrace/obslab-predictive-kubernetes-scaling/main/docs/images/pull-request.png)\\n\",\"type\":\"markdown\"},{\"id\":\"992ba2eb-1ec3-4d42-a078-0e13568387ce\",\"markdown\":\"## 5. Emit Info Event\\n\\nAs a final step, the second workflow emits an additional event of type `CUSTOM_INFO`. This event serves as a record of the scaling PR being created and includes details about the associated workload and the changes made. While not triggering any further automations, this event is attached to the relevant workload and can be queried in Dynatrace for auditing and reporting purposes.\\n\\nExecute the following DQL query to preview these events:\\n\",\"type\":\"markdown\"},{\"height\":250,\"id\":\"97e574bd-e2c4-427e-b05a-945a93cf6a52\",\"showTitle\":false,\"state\":{\"input\":{\"timeframe\":{\"from\":\"now()-1h\",\"to\":\"now()\"},\"value\":\"fetch events\\n| filter event.type == \\\"CUSTOM_INFO\\\" and kubernetes.predictivescaling.type == \\\"SUGGEST_SCALING\\\"\\n| fields\\n  timestamp,\\n  event.name,\\n  event.category,\\n  event.type,\\n  kubernetes.predictivescaling.workload.cluster.name,\\n  kubernetes.predictivescaling.workload.cluster.id,\\n  kubernetes.predictivescaling.workload.kind,\\n  kubernetes.predictivescaling.workload.namespace,\\n  kubernetes.predictivescaling.workload.name,\\n  kubernetes.predictivescaling.workload.uuid,\\n  kubernetes.predictivescaling.workload.limits.memory,\\n  kubernetes.predictivescaling.workload.limits.cpu,\\n  kubernetes.predictivescaling.prediction.type,\\n  kubernetes.predictivescaling.prediction.prompt,\\n  kubernetes.predictivescaling.prediction.description,\\n  kubernetes.predictivescaling.prediction.suggestions,\\n  kubernetes.predictivescaling.target.uuid,\\n  kubernetes.predictivescaling.target.repository,\\n  kubernetes.predictivescaling.pullrequest.id,\\n  kubernetes.predictivescaling.pullrequest.url\"},\"visualization\":\"table\"},\"type\":\"dql\"}],\"version\":\"6\"}",
            "id": "7c5438c8-8dbc-441c-a58c-bef52585b557",
            "name": "Predictive Kubernetes Scaling",
            "owner": "e641aa5e-dcc4-42e7-b87e-225a1ea96330",
            "private": true,
            "type": "notebook",
            "version": 1
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "dynatrace_api_token.manage_workflows"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_generic_setting",
      "name": "github_credentials",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "id": "vu9U3hXa3q0AAAABAClhcHA6ZHluYXRyYWNlLmdpdGh1Yi5jb25uZWN0b3I6Y29ubmVjdGlvbgAGdGVuYW50AAZ0ZW5hbnQAJGM4ZjY3OGE5LTZhM2UtMzg1Yy05MjM5LTA1MGVjMWU1OTQyNL7vVN4V2t6t",
            "local_storage": "{\"name\":\"Default Connection [Predictive Kubernetes Scaling]\",\"token\":\"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\",\"type\":\"pat\"}",
            "schema": "app:dynatrace.github.connector:connection",
            "scope": "environment",
            "value": "{\"name\":\"Default Connection [Predictive Kubernetes Scaling]\",\"token\":\"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\",\"type\":\"pat\"}"
          },
          "sensitive_attributes": [
            [
              {
                "type": "get_attr",
                "value": "value"
              }
            ]
          ],
          "private": "bnVsbA==",
          "dependencies": [
            "dynatrace_api_token.manage_workflows"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "dynatrace_ownership_teams",
      "name": "demo",
      "provider": "provider[\"registry.terraform.io/dynatrace-oss/dynatrace\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "additional_information": [],
            "contact_details": [],
            "description": "Predictive Kubernetes Scaling demo team",
            "external_id": "",
            "id": "vu9U3hXa3q0AAAABABdidWlsdGluOm93bmVyc2hpcC50ZWFtcwAGdGVuYW50AAZ0ZW5hbnQAJGNkNTk1ZDNhLTgyMDEtMzRhYy1iMDg0LTJjNDI0N2MzYWY3Zb7vVN4V2t6t",
            "identifier": "predictive-kubernetes-scaling",
            "links": [],
            "name": "predictive-kubernetes-scaling",
            "responsibilities": [
              {
                "development": true,
                "infrastructure": false,
                "line_of_business": false,
                "operations": true,
                "security": false
              }
            ],
            "supplementary_identifiers": []
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "dynatrace_api_token.manage_workflows"
          ]
        }
      ]
    }
  ],
  "check_results": null
}
